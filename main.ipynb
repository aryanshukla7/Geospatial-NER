{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l17WznaGAB5s",
        "outputId": "2dc13c30-16fb-41b2-d2ff-e2e0b795218e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tpW5nkMc53m",
        "outputId": "15334ab8-34f9-43e6-f707-6a6c4facec7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.8/453.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.1.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.23.0 rapidfuzz-3.5.2\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.3.0 spark-nlp==4.2.8\n",
        "!pip install Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIGUfEtSDbEi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sparknlp\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from pyspark.sql.types import StringType, IntegerType\n",
        "from transformers import pipeline\n",
        "import Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbNneAVCLU1y"
      },
      "outputs": [],
      "source": [
        "spark = sparknlp.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvn2hTw6DbIH",
        "outputId": "7fe1a39d-a59f-4e1c-ee91-0f1ec3d2b133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert_token_classifier_hi_en_ner download started this may take some time.\n",
            "Approximate size to download 634.9 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "        .setInputCol('text')\\\n",
        "        .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "        .setInputCols(['document'])\\\n",
        "        .setOutputCol('sentence')\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "        .setInputCols(['sentence']) \\\n",
        "        .setOutputCol('token')\n",
        "\n",
        "tokenClassifier_loaded = BertForTokenClassification.pretrained(\"bert_token_classifier_hi_en_ner\",\"hi\")\\\n",
        "        .setInputCols([\"sentence\",'token'])\\\n",
        "        .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "        .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
        "        .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "nlp_pipeline = Pipeline(stages=[document_assembler,\n",
        "                                sentence_detector,\n",
        "                                tokenizer,\n",
        "                                tokenClassifier_loaded,\n",
        "                                ner_converter])\n",
        "\n",
        "checkpoint = \"/content/drive/MyDrive/Dead_line ISRO/distilbert-finetuned-ner-2/checkpoint-3135\"\n",
        "token_classifier = pipeline(\n",
        "    \"token-classification\", model=checkpoint, aggregation_strategy=\"simple\"\n",
        ")\n",
        "\n",
        "# text_list =[\"\"\"वॉरेन एडवर्ड बफेट (Warren Buffet) (अगस्त 30 (August 30), 1930 को ओमाहा (Omaha), नेब्रास्का (Nebraska) में पैदा हुए) एक अमेरिकी निवेशक (investor), व्यवसायी और परोपकारी (philanthropist) व्यक्तित्व हैं।\"\"\"]\n",
        "\n",
        "# df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n",
        "# result = nlp_pipeline.fit(df).transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Swe8hQKTokWW"
      },
      "outputs": [],
      "source": [
        "# text_list =[\"Are Jaipur and Ajmer the same state?\"]\n",
        "# text_list = [\"AMong jaipur, Ajmer and Baroda whih of these have a higher population than Surat\"]\n",
        "# text_list = [\"Which has higher average temperature in June, AHmedabad or Gandhinagar\"]\n",
        "# text_list = [\"Where is zebara? is it in amdavad?\"]\n",
        "# text_list = [\"The new england journal of medicine is the best medical journal in the world\"]\n",
        "# text_list = [\"Can I visit new york, mars, sun and delhi on the same day?\"]\n",
        "# text_list = [\"Can I visit new york mars sun and delhi on the same day?\"]\n",
        "# text_list = [\"where can i find lakes near Ahmedabad\"]\n",
        "# text_list = [\"where can I find lakes near Amdavad\"]\n",
        "# text_list = [\"is there water in delli?\"]\n",
        "# text_list = [\"Is it a good time to visit Prince edward island?\"]\n",
        "# text_list = [\"which has higher average temperature in june, ahmedabad or gandhinagar\"]\n",
        "# text_list = [\"Which Has Higher Average Temperature In June, Ahmdvad Or Gandhingr\"]\n",
        "# text_list = [\"temperature at amdavad is high\"]\n",
        "# text_list = [\"The zoo is located in Abc\"]\n",
        "# text_list = [\"The zoo is located in Abc\"]\n",
        "# text_list = [\"अहमदाबाद का तापमान मध्य प्रदेश से भी ज्यादा है\"]\n",
        "# text_list = [\"अमदाबद का तापमान मध्यदेश से भी ज्यादा है\"]\n",
        "# text_list = [\"Name of my daughter is India\"]\n",
        "# text_list = [\"I hate Gujarat but i love faafada\"]\n",
        "# text_list = [\"Anjeer is my favourite\"]\n",
        "# text_list = [\"Farah Went To Kushk\"]\n",
        "# text_list = [\"Temperature At Abc Is Higher Than Temperature at xyz\"]\n",
        "# text_list = [\"Venus has a travel planned to mars\"]\n",
        "# text_list = [\"The dal lake is in sri nagar\"]\n",
        "# text_list = [\"What happened in Tamil Nadu\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkIYifAmJMYS"
      },
      "outputs": [],
      "source": [
        "import codecs,string\n",
        "def is_hindi(character):\n",
        "    maxchar = max(character)\n",
        "    if u'\\u0900' <= maxchar <= u'\\u097f':\n",
        "        return True\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "def findword(text, s, e):\n",
        "  while s>0 and text[s-1] != ' ' and text[s-1] != ',' and text[s-1] != '.' and text[s-1] != '?':\n",
        "    s-=1\n",
        "  while e<len(text) and text[e] != ' ' and text[e] != ',' and text[e] != '.' and text[e] != '?':\n",
        "    e+=1\n",
        "  return text[s:e]\n",
        "\n",
        "def combinedOutput(extracted_list, output, text_list):\n",
        "  namelist1 = {}\n",
        "  # print(extracted_list, output)\n",
        "  for out in extracted_list:\n",
        "    # print(out)\n",
        "    namelist1[out[0].lower()] = out[1]\n",
        "\n",
        "  namelist2 = {}\n",
        "  for out in output:\n",
        "    # if out['score'] > 0.70:\n",
        "      # print(\"printing out\", out)\n",
        "      word = findword(text_list[0].lower(), out['start'], out['end'])\n",
        "      # print(word)\n",
        "      namelist2[word] =  out['score']\n",
        "\n",
        "  # print(namelist2)\n",
        "  # print(namelist1)\n",
        "  result = {}\n",
        "  for place in namelist2.keys():\n",
        "    if is_hindi(place):\n",
        "      continue\n",
        "    if place not in namelist1.keys():\n",
        "      result[place] = \"Looks Like\"\n",
        "\n",
        "    elif namelist1[place] == 'PLACE':\n",
        "      result[place] = \"Certain\"\n",
        "    else:\n",
        "      result[place] = f'{place} occurs in the context of {namelist1[place]} but its name may resemble the name of a place'\n",
        "\n",
        "  for place in namelist1.keys():\n",
        "    if namelist1[place] == 'PLACE' and place not in result.keys():\n",
        "      result[place] = \"Most Likely\"\n",
        "      if len(place.split(' ')) > 1:\n",
        "        for x in place.split(' '):\n",
        "          if x in result.keys():\n",
        "            del result[x]\n",
        "\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lsRMBgB0OBm"
      },
      "outputs": [],
      "source": [
        "def getNER(text):\n",
        "  text = text.capitalize()\n",
        "  # print(text)\n",
        "  text_list = [text]\n",
        "  df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n",
        "  result = nlp_pipeline.fit(df).transform(df)\n",
        "\n",
        "\n",
        "  extracted_result = result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.metadata)).alias(\"cols\")) \\\n",
        "    .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "            F.expr(\"cols['1']['entity']\").alias(\"ner_label\"))\n",
        "  # extracted_result.show(truncate=False)\n",
        "\n",
        "  extracted_list = extracted_result.collect()\n",
        "\n",
        "  checkpoint = \"/content/drive/MyDrive/Dead_line ISRO/distilbert-finetuned-ner-2/checkpoint-3135\"\n",
        "  token_classifier = pipeline(\n",
        "      \"token-classification\", model=checkpoint, aggregation_strategy=\"simple\"\n",
        "  )\n",
        "\n",
        "  output = token_classifier(text_list[0].lower())\n",
        "  # print(extracted_list, output)\n",
        "  answer = combinedOutput(extracted_list, output, text_list)\n",
        "  return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCtJ2op21PZs",
        "outputId": "9cfd6d50-c20e-4f2b-ba83-56bc81752426"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'surat is a city in dujrat': 'Looks Like',\n",
              " 'surat': 'Most Likely',\n",
              " 'dujrat': 'Most Likely'}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getNER(\"surat is a city in dujrat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZr3Anr1q6k1"
      },
      "outputs": [],
      "source": [
        "# The function to find similarity between correctAnswer and userAnswer, based on levenshtein distance\n",
        "def validate_answer_levenshtein(correct_answer, user_answer, threshold=80):\n",
        "    distance = Levenshtein.distance(user_answer.lower(), correct_answer.lower())\n",
        "    similarity = 1 - (distance / max(len(user_answer), len(correct_answer)))\n",
        "    # normalising from [0,1] to [0,100]\n",
        "    return round(100*similarity, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiQrxJI_qNxy"
      },
      "outputs": [],
      "source": [
        "def fuzzyMatching(fuzzy_li, universe_of_names):\n",
        "    global_nearest_match_li = []\n",
        "    max_similarity = 0\n",
        "\n",
        "    for word in fuzzy_li:\n",
        "        nearest_match_li = []\n",
        "        n = 0\n",
        "        for checking_word, type_ in universe_of_names:\n",
        "            temp = validate_answer_levenshtein(word, checking_word)\n",
        "            if n == 0:\n",
        "                nearest_match_li.append((checking_word, temp, type_))\n",
        "                n += 1\n",
        "            else:\n",
        "                for i in range(n):\n",
        "                    # print(len(nearest_match_li), n)\n",
        "                    if temp >= nearest_match_li[i][1]:\n",
        "                        nearest_match_li.insert(i, (checking_word, temp, type_))\n",
        "                        n += 1\n",
        "                        break\n",
        "                else:\n",
        "                    nearest_match_li.append((checking_word, temp, type_))\n",
        "                    n += 1\n",
        "            if n == 4:\n",
        "                nearest_match_li = nearest_match_li[:-1]\n",
        "                n -= 1\n",
        "        global_nearest_match_li.append(nearest_match_li)\n",
        "\n",
        "    return global_nearest_match_li"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgyE9FXu40ew"
      },
      "outputs": [],
      "source": [
        "def fuzzyMatchingPreprocessing():\n",
        "\n",
        "    countries_df = pd.read_csv(\"/content/drive/MyDrive/Dead_line ISRO/Matching Tables/countries.csv\")\n",
        "    states_df = pd.read_csv(\"/content/drive/MyDrive/Dead_line ISRO/Matching Tables/states.csv\")\n",
        "    cities_df = pd.read_csv(\"/content/drive/MyDrive/Dead_line ISRO/Matching Tables/cities.csv\")\n",
        "\n",
        "\n",
        "    n_cities = len(cities_df)\n",
        "    n_states = len(states_df)\n",
        "    n_countries = len(countries_df)\n",
        "\n",
        "    cities_list = [(cities_df.iloc[i][\"name\"].lower(), \"city\") for i in range(n_cities)]\n",
        "    states_list = [(states_df.iloc[i][\"name\"].lower(), \"state\") for i in range(n_states)]\n",
        "    countries_list = [(countries_df.iloc[i][\"name\"].lower(), \"country\") for i in range(n_countries)]\n",
        "\n",
        "    universe_of_names = countries_list + states_list + cities_list\n",
        "    return universe_of_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfIG_TnR5WRG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwXlmEu8ILK6"
      },
      "outputs": [],
      "source": [
        "def fuzzyMatchingComplete (fuzzy_li, universe_of_names):\n",
        "\n",
        "    final_list = fuzzyMatching(fuzzy_li, universe_of_names)\n",
        "\n",
        "    return final_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bq6zVDVCSit"
      },
      "outputs": [],
      "source": [
        "def add(word,entity,universe_of_names):\n",
        "  entry = (word.lower(), entity.lower())\n",
        "  if entry in universe_of_names:\n",
        "      print(entry, \" is already present in the database\")\n",
        "  else:\n",
        "      universe_of_names.append(entry)\n",
        "  return universe_of_names\n",
        "\n",
        "def delete(word,entity,universe_of_names):\n",
        "  entry = (word.lower(), entity.lower())\n",
        "  if entry not in universe_of_names:\n",
        "    print(tuple([word,entity.lower()]), \" is not present in the database\")\n",
        "  else:\n",
        "    universe_of_names.remove(entry)\n",
        "  return universe_of_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si6d5ELgExUm"
      },
      "outputs": [],
      "source": [
        "universe_of_names = fuzzyMatchingPreprocessing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gHLWIL3I04x"
      },
      "outputs": [],
      "source": [
        "def main(universe_of_names):\n",
        "  while True:\n",
        "      # Take input from the user\n",
        "      print(\"\")\n",
        "\n",
        "      request_type = input(\"Enter a request type: (Entering sentence: 1, add to database: 2, delete to database: 3), (exit: -1) : \")\n",
        "      print(\"\")\n",
        "      if request_type == '-1':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "      elif request_type == '1' :\n",
        "        user_input = input(\"Enter a sentence (type '-1' to exit): \")\n",
        "\n",
        "        # Check if the user wants to exit\n",
        "        if user_input == '-1':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        # Call the processing function and display the result\n",
        "        result = getNER(user_input)\n",
        "        # print(f\"Result: {result}\")\n",
        "\n",
        "        matched_cities = fuzzyMatchingComplete(result.keys(), universe_of_names)\n",
        "\n",
        "        print(result)\n",
        "        print()\n",
        "        i=0\n",
        "        for entity in result.keys():\n",
        "          print(\"matching places for \", entity, \" are : \", matched_cities[i])\n",
        "          i+=1\n",
        "          print()\n",
        "      elif request_type == '2':\n",
        "        user_input = input(\"Enter the name of the place (type '-1' to exit): \")\n",
        "        print(\"\")\n",
        "        user_category = input(\"Enter the type of place(city, state, country)  (type '-1' to exit): \")\n",
        "        print(\"\")\n",
        "        if user_input == '-1' or user_category == '-1':\n",
        "          break\n",
        "        universe_of_names = add(user_input, user_category, universe_of_names)\n",
        "\n",
        "      elif request_type == \"3\":\n",
        "        user_input = input(\"Enter the name of the place  (type '-1' to exit): \")\n",
        "        print(\"\")\n",
        "        user_category = input(\"Enter the type of place(city, state, country)  (type '-1' to exit): \")\n",
        "        print(\"\")\n",
        "        if user_input == '-1' or user_category == '-1':\n",
        "          break\n",
        "        universe_of_names = delete(user_input, user_category, universe_of_names)\n",
        "      else:\n",
        "        print(\"Please enter a valid input\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ8b2vFK09qo",
        "outputId": "f22f4a81-5639-4dea-a8fa-0853cf85100a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "{'dadra': 'Most Likely', 'nagra': 'Most Likely', 'ladakh': 'Most Likely'}\n",
            "\n",
            "matching places for  dadra  are :  [('Dadra', 100.0, 'city'), ('Adra', 80.0, 'city'), ('Dara', 80.0, 'city')]\n",
            "\n",
            "matching places for  nagra  are :  [('Neagra', 83.33, 'city'), ('Nagram', 83.33, 'city'), ('Zagra', 80.0, 'city')]\n",
            "\n",
            "matching places for  ladakh  are :  [('Ladakh', 100.0, 'city'), ('Ladakh', 100.0, 'state'), ('Ladan', 66.67, 'city')]\n",
            "\n",
            "\n",
            "\n",
            "{'dadra': 'Certain', 'nagra': 'Most Likely', 'ladakh': 'Most Likely', 'telangana': 'Most Likely'}\n",
            "\n",
            "matching places for  dadra  are :  [('Dadra', 100.0, 'city'), ('Adra', 80.0, 'city'), ('Dara', 80.0, 'city')]\n",
            "\n",
            "matching places for  nagra  are :  [('Neagra', 83.33, 'city'), ('Nagram', 83.33, 'city'), ('Zagra', 80.0, 'city')]\n",
            "\n",
            "matching places for  ladakh  are :  [('Ladakh', 100.0, 'city'), ('Ladakh', 100.0, 'state'), ('Ladan', 66.67, 'city')]\n",
            "\n",
            "matching places for  telangana  are :  [('Telangana', 100.0, 'state'), ('Kalanganan', 70.0, 'city'), ('Taranganba', 70.0, 'city')]\n",
            "\n",
            "\n",
            "\n",
            "Please enter a valid input\n",
            "\n",
            "\n",
            "{'dadra': 'Certain', 'nagra': 'Most Likely'}\n",
            "\n",
            "matching places for  dadra  are :  [('Dadra', 100.0, 'city'), ('Adra', 80.0, 'city'), ('Dara', 80.0, 'city')]\n",
            "\n",
            "matching places for  nagra  are :  [('Neagra', 83.33, 'city'), ('Nagram', 83.33, 'city'), ('Zagra', 80.0, 'city')]\n",
            "\n",
            "\n",
            "\n",
            "Please enter a valid input\n",
            "\n",
            "\n",
            "{'dadra': 'Certain', 'nagar haveli': 'Most Likely'}\n",
            "\n",
            "matching places for  dadra  are :  [('Dadra', 100.0, 'city'), ('Adra', 80.0, 'city'), ('Dara', 80.0, 'city')]\n",
            "\n",
            "matching places for  nagar haveli  are :  [('Dadra & Nagar Haveli', 60.0, 'city'), ('Fair Haven', 58.33, 'city'), ('Fair Haven', 58.33, 'city')]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "main(universe_of_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "EMv0JQrtay4R",
        "outputId": "e92aa4f5-4c8b-4af4-db32-a2f1f9736500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "{'india': 'Certain'}\n",
            "\n",
            "matching places for  india  are :  [('India', 100.0, 'country'), ('Sindia', 83.33, 'city'), ('Kindia', 83.33, 'city')]\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-18213b388a1e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniverse_of_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-032f815731a7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(universe_of_names)\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mrequest_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter a request type: (Entering sentence: 1, add to database: 2, delete to database: 3), (exit: -1) : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrequest_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'-1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "main(universe_of_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UGVMKWRbf-I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}